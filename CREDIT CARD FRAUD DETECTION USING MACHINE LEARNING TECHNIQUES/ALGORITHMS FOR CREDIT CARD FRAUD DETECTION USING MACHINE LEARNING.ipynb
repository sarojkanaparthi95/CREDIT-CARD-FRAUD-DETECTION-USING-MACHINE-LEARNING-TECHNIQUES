{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Step 1: Import the required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplotting\u001b[39;00m \u001b[39mimport\u001b[39;00m scatter_matrix\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the required libraries\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from collections import Counter\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import the plot_functions module\n",
    "import plot_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Import scikit-learn packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Configure settings for visualizations\n",
    "%matplotlib inline\n",
    "sn.set_style(\"dark\")\n",
    "sn.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load the credit card dataset from a CSV file\n",
    "df = pd.read_csv(\"data/creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Print information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Print the counts of normal and fraudulent transactions\n",
    "print('Normal transactions count: ', df['Class'].value_counts().values[0])\n",
    "print('Fraudulent transactions count: ', df['Class'].value_counts().values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Create the feature matrix X and target vector y\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Perform oversampling on the training data using ADASYN\n",
    "ada = ADASYN(random_state=42)\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "X_res, y_res = ada.fit_sample(X_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Update the training data with the resampled data\n",
    "X_train, y_train = X_res, y_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Train the LogisticRegression model\n",
    "LGR_Classifier = LogisticRegression()\n",
    "LGR_Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Train the RandomForestClassifier model\n",
    "RDF_Classifier = RandomForestClassifier(random_state=0)\n",
    "RDF_Classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Train the BernoulliNB model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Create a list of models for evaluation\n",
    "modlist = [('RandomForest Classifier', RDF_Classifier),('LogisticRegression', LGR_Classifier), ('Naive Baiye Classifier', BNB_Classifier)] \n",
    "models = [j for j in modlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 18: Print model evaluation results\n",
    "print('\\n========================== Model Evaluation Results ========================\\n')\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_train))\n",
    "    print('===== {} ====='.format(i))\n",
    "    print()\n",
    "    print(\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))\n",
    "    print()\n",
    "    print(\"Model Accuracy: \", '{}%'.format(np.round(accuracy, 3) * 100))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification Report:\\n\", classification)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 19: Test the models on the testing data and print the results\n",
    "classdict = {'normal':0, 'fraudulent':1}\n",
    "print('\\n========================== Model Test Results ========================\\n')\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_test))\n",
    "    print('=== {} ==='.format(i))\n",
    "    print()\n",
    "    print(\"Model Accuracy: \", '{}%'.format(np.round(accuracy, 3) * 100))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    print()\n",
    "    pf.plot_confusion_matrix(confusion_matrix, classes = list(classdict.keys()), title='Confusion Matrix Plot', cmap=plt.cm.summer)\n",
    "    print()\n",
    "    print(\"Classification Report:\\n\", classification)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 20: Plot the ROC curve\n",
    "print('\\n============================= ROC Curve ===============================\\n')\n",
    "pf.plot_roc_auc(arg1=models, arg2=X_test, arg3=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
